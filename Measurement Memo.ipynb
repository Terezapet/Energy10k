{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measurement Memo \n",
    "## Tereza Petrovicova \n",
    "### November 5\n",
    "\n",
    "*In this measurement memo, you will create a measure from your data.  Please submit your R code along with your memo (you do not have to submit your data). Decide on something you'd like to measure within your data that could be achieved by hand coding.*\n",
    "\n",
    "For this project, I am analyzing regulatory exposure related to energy regulations within companies' annual 10-K filings. These 10-K reports are comprehensive and often contain large sections dedicated to financial details, which would be overwhelming and unnecessary for human coders to read in full. Therefore, I first narrowed my extraction to the most relevant section: Item 1A - Risk Factors. This section is mandated by the SEC and requires companies to disclose any potential risks they face, making it a concentrated source of regulatory information.\n",
    "\n",
    "After extracting the Risk Factors section, I found that even this section averages around two pages per document. Therefore, I split each Risk Factors section into chunks of 10 sentences. This breakdown should make it easier for coders to work through the text systematically without being overwhelmed by lengthy passages, while still retaining the nuanced context needed to assess regulatory exposure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A: Creating a Codebook\n",
    "\n",
    "I am interested in measuring environmental and energy regulatory discourse in 10Ks. I am first trying to caputrue whether there is any of this discourse happening, and then seeing whether it is possible ti disentangle between environemnral and energy regulation. Then finally I am trying to see whether this regulation happens at different government levels (federal, state, local). I am also creating a category of cost, where I want to see whether the regulation poses a direct cost to the company, or is merely stated as something that may impact/disrupt business. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Variable Name**          | **Description**                                                                                         | **Coding**                                 | **Example Keywords/Indicators**                                     |\n",
    "|----------------------------|---------------------------------------------------------------------------------------------------------|--------------------------------------------|---------------------------------------------------------------------|\n",
    "| **Regulation_Present**     | Indicates if there is a discussion of environmental or energy regulation specifically                   | 1 = Yes<br>0 = No                          | \"environmental regulation,\" \"energy regulation,\" \"EPA,\" \"FERC\"      |\n",
    "| **Regulation_Type**        | Specifies the type of regulation discussed: environmental, energy, both, or unclear                     | 1 = Environmental<br>2 = Energy<br>3 = Both<br>0 = None | \"environmental standards,\" \"pollution control,\" \"FERC,\" \"energy grid,\" \"electricity rates\" |\n",
    "| **Regulation_Cost**        | Indicates if regulation is framed as a cost or burden to the company                                    | 1 = Yes<br>0 = No                          | \"cost,\" \"compliance burden,\" \"penalty,\" \"increased expenses\"        |\n",
    "| **Federal_Regulation**     | Indicates the presence of federal-level regulation (mentions of agencies like EPA, FERC)                | 1 = Yes<br>0 = No                          | \"federal,\" \"EPA,\" \"FERC\"                                            |\n",
    "| **State_Regulation**       | Indicates the presence of state-level regulation discussion                                             | 1 = Yes<br>0 = No                          | \"state regulation,\" \"public utility commission,\" \"Renewable Portfolio Standard (RPS)\" |\n",
    "| **Local_Regulation**       | Indicates the presence of local-level regulation discussion                                             | 1 = Yes<br>0 = No                      | \"zoning ordinances\", \"local regulation\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "** if regulation_present is 0 then all following variables are also 0\n",
    "\n",
    "### Detailed Explanation of each Category:\n",
    "1.\t**Regulation_Present** -  This binary variable captures the presence of either environmental or energy regulation specifically within the text. For an entry to be coded as \"1,\" there must be an explicit reference to regulatory terms that are clearly related to environmental or energy concerns. General mentions of \"governmental regulation\" or similar non-specific terms are not included here. Examples of indicators include references to specific agencies or terms like \"EPA regulations\" or \"energy compliance.\"\n",
    "\n",
    "2.\t**Regulation_Type** - This variable distinguishes the type of regulation being discussed if it can be identified. It’s coded as:\n",
    "- 1 for Environmental Regulation, which includes mentions of regulations or policies aimed at environmental protection, pollution control, emissions standards, clean water standards, etc.\n",
    "- \t2 for Energy Regulation, which includes policies governing the production, transmission, and distribution of energy, such as FERC rules or electricity rate standards.\n",
    "-\t3 if both types are mentioned together in the text.\n",
    "-\t0 if neither type is mentioned or if the regulation is unclear.\n",
    "\n",
    "3.\t**Regulation_Cost** - This variable indicates if the regulation is framed as imposing a direct cost or burden on the company. The text should clearly indicate that the regulation results in financial expenses, increased operational costs, or requirements for additional resources. Indicators include phrases like \"increased cost,\" \"compliance burden,\" or \"cost of raw inputs.\"\n",
    "\n",
    "4.\t**Federal_Regulation** - This variable captures mentions of federal-level regulation or oversight. Indicators include explicit references to federal agencies such as the Environmental Protection Agency (EPA) or the Federal Energy Regulatory Commission (FERC), or mentions of federal regulations in a way that clarifies the jurisdiction. It’s coded as \"1\" for presence and \"0\" otherwise.\n",
    "\n",
    "5.\t**State_Regulation** - This binary variable identifies whether there is a mention of state-level regulatory policies. It captures regulations at the state level, such as Renewable Portfolio Standards (RPS) or state environmental agencies. Mentions of specific state entities, state mandates, or compliance with state laws are key indicators.\n",
    "\n",
    "6.\t**Local_Regulation** - This variable captures mentions of local-level regulations, such as city ordinances or county-level environmental policies. The text should refer explicitly to local jurisdictions, entities, or ordinances. It is coded as \"1\" if present and \"0\" if absent.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Selecting Training Set \n",
    "\n",
    "This section is divided into two parts, pre-rpocessing and selecting 50 chunks of text at random.\n",
    "\n",
    "### Pre-processing\n",
    "In this section I am pre-processing the 10ks, which are really long. So I just decided to focus on \"Item 1A: Risk Factors.\" I then divided each document into chunks of 10 sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Set the working directory\n",
    "os.chdir(\"/Users/teri/Documents/GitHub/Energy10k\")\n",
    "\n",
    "# Read metadata \n",
    "metadata = pd.read_csv(\"metadata2024.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define a function to extract the \"Risk Factors\" section and set a flag for missing items\n",
    "def extract_risk_section(text):\n",
    "    # Step 1: Search for \"ITEM 1A.RISK FACTORS\" in the document\n",
    "    risk_start = re.search(r'Item\\s*1A\\s*\\.\\s*Risk\\s*Factors', text, re.IGNORECASE)\n",
    "    \n",
    "    # Initialize a flag for successful extraction\n",
    "    extraction_successful = True\n",
    "\n",
    "    # Step 2: If found, slice from that position\n",
    "    if risk_start:\n",
    "        start_idx = risk_start.start()\n",
    "        \n",
    "        # Try finding the next section (often \"Item 1B\") to mark the end of the Risk Factors section\n",
    "        next_item_1b = re.search(r'Item\\s*1B\\s*\\.', text[start_idx:], re.IGNORECASE)\n",
    "        \n",
    "        # If \"Item 1B\" is not found, look for \"Item 2\"\n",
    "        if next_item_1b:\n",
    "            end_idx = start_idx + next_item_1b.start()\n",
    "        else:\n",
    "            next_item_2 = re.search(r'Item\\s*2\\s*\\.', text[start_idx:], re.IGNORECASE)\n",
    "            if next_item_2:\n",
    "                end_idx = start_idx + next_item_2.start()\n",
    "            else:\n",
    "                # If neither \"Item 1B\" nor \"Item 2\" is found, mark extraction as unsuccessful\n",
    "                extraction_successful = False\n",
    "                end_idx = len(text)  # If neither \"Item 1B\" nor \"Item 2\" is found, take the rest of the text\n",
    "\n",
    "        risk_text = text[start_idx:end_idx]\n",
    "        return risk_text, extraction_successful\n",
    "    else:\n",
    "        # Mark extraction as unsuccessful if \"Item 1A.RISK FACTORS\" section is not found\n",
    "        return None, False\n",
    "\n",
    "# Apply the function to the 'text' column and filter out unsuccessful extractions\n",
    "metadata[['risk_text', 'extraction_successful']] = metadata.apply(\n",
    "    lambda row: pd.Series(extract_risk_section(row['text'])), axis=1\n",
    ")\n",
    "\n",
    "# Drop rows where extraction was unsuccessful\n",
    "metadata_filtered = metadata[metadata['extraction_successful']]\n",
    "\n",
    "# Drop the 'extraction_successful' column as it's no longer needed\n",
    "metadata_filtered = metadata_filtered.drop(columns=['extraction_successful'])\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "#metadata_filtered[['accession', 'time', 'ticker', 'naics', 'risk_text']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ticker  risk_word_count                                          risk_text\n",
      "0      AEE            10026  ITEM 1A. RISK FACTORS Investors should review ...\n",
      "1      AEP            11158  ITEM 1A.   RISK FACTORS GENERAL RISKS OF REGUL...\n",
      "2      AES            12948  ITEM 1A. RISK FACTORS You should consider care...\n",
      "3      AGR             8158  Item 1A. Risk Factors You should carefully con...\n",
      "4      ALE             7620  Item 1A. Risk Factors The risks and uncertaint...\n",
      "..     ...              ...                                                ...\n",
      "144    VGZ             5462  Item 1A. Risk Factors” below in this annual re...\n",
      "145    VMC                0                                               None\n",
      "146    VST            27854  Item 1A. Risk Factors for additional informati...\n",
      "147    WEC            21072  Item 1A. Risk Factors - Risks Related to Legis...\n",
      "148    WTI            18131  Item 1A. Risk Factors contained herein for fur...\n",
      "\n",
      "[149 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define a function to count words in a text\n",
    "def word_count(text):\n",
    "    if text:\n",
    "        return len(text.split())\n",
    "\n",
    "    return 0  # Return 0 if text is None\n",
    "\n",
    "# Apply the word count function to the 'risk_text' column\n",
    "metadata['risk_word_count'] = metadata['risk_text'].apply(word_count)\n",
    "\n",
    "# Display the accession, ticker, and word count for each entry\n",
    "print(metadata[['ticker', 'risk_word_count', 'risk_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the text content for the specified ticker\n",
    "#awk_text = metadata[metadata['ticker'] == 'AEE']['risk_text'].values[0]\n",
    "\n",
    "# Display the last 500 characters\n",
    "#print(awk_text[-500:])\n",
    "metadata = metadata.drop(columns=['text'])\n",
    "metadata.to_csv(\"reg_expo_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split into chunks of 10 sentences \n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Ensure the punkt tokenizer is downloaded\n",
    "#nltk.download('punkt')\n",
    "\n",
    "# Function to split text into chunks of 10 sentences\n",
    "def split_text_into_chunks(text, chunk_size=10):\n",
    "    if text is None:\n",
    "        return []  # Return an empty list if the text is None\n",
    "    sentences = sent_tokenize(text)  # Split text into sentences\n",
    "    chunks = [sentences[i:i + chunk_size] for i in range(0, len(sentences), chunk_size)]\n",
    "    return [\" \".join(chunk) for chunk in chunks]  # Join sentences back into chunk strings\n",
    "\n",
    "# Create a new DataFrame to hold the chunked data\n",
    "chunked_data = []\n",
    "\n",
    "# Iterate over each row and split 'risk_text' into chunks\n",
    "for idx, row in metadata.iterrows():\n",
    "    chunks = split_text_into_chunks(row['risk_text'], 10)\n",
    "    chunk_dict = {'ticker': row['ticker']}  # Start with ticker\n",
    "    # Add each chunk to the dictionary\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_dict[f'chunk_{i+1}'] = chunk\n",
    "    chunked_data.append(chunk_dict)\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "chunked_df = pd.DataFrame(chunked_data)\n",
    "\n",
    "# Concatenate with original DataFrame, removing 'risk_text' if not needed\n",
    "metadata_new = pd.concat([metadata.drop(columns=['risk_text']), chunked_df.drop(columns=['ticker'])], axis=1)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "#metadata_new.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Risk sections DataFrame to a CSV file, removing the full text of the 10k\n",
    "#metadata_new = metadata_new.drop(columns=['risk_text'])\n",
    "metadata_new.to_csv(\"reg_expo_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting 50 Chunks at Random\n",
    "\n",
    "In the code Below I randomly selected a training set of 50 samples of 10 sentences each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your DataFrame is named `metadata_filtered`\n",
    "# Reshape the DataFrame to have one chunk per row along with the ticker\n",
    "\n",
    "# Melt the DataFrame to convert all chunk columns into rows\n",
    "chunk_columns = [col for col in metadata_new.columns if col.startswith('chunk_')]\n",
    "reshaped_df = metadata_new.melt(id_vars=['ticker'], value_vars=chunk_columns, \n",
    "                                     var_name='chunk_number', value_name='chunk_text')\n",
    "\n",
    "# Drop any rows where 'chunk_text' is NaN (empty chunks)\n",
    "reshaped_df = reshaped_df.dropna(subset=['chunk_text'])\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "seed = 45\n",
    "\n",
    "# previous seed was 42 - for the sample of 50\n",
    "\n",
    "# Randomly sample 50 rows, ensuring we only pick one chunk per company\n",
    "sampled_chunks = reshaped_df.groupby('ticker').sample(n=1, random_state=seed).sample(n=130, random_state=seed)\n",
    "\n",
    "# Display the sampled chunks\n",
    "sampled_chunks = sampled_chunks.reset_index(drop=True)\n",
    "sampled_chunks[['ticker', 'chunk_text']]\n",
    "\n",
    "# Save into .csv file\n",
    "sampled_chunks.to_csv(\"sample130.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C and D: Human Coding and Intercoder Reliability\n",
    "\n",
    "I first coded the 50 randomly selected chunks, and I also got Harry to do the same. I then combined our results into one dataframe and ran intercoder reliability tests on our results. In particular, I created a confusion matrix and calculated krippendorff's alpha for each variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for regulation_present:\n",
      " [[27  0]\n",
      " [ 6 17]]\n",
      "Krippendorff's alpha for regulation_present: 0.7525\n",
      "Mismatches between coders for regulation_present:\n",
      "    ticker  regulation_present_coder1  regulation_present_coder2\n",
      "0     MGY                          1                          0\n",
      "3     EOG                          1                          0\n",
      "20   SMLP                          1                          0\n",
      "27   LBRT                          1                          0\n",
      "33    RRC                          1                          0\n",
      "49    CPK                          1                          0\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Confusion Matrix for regulation_type:\n",
      " [[28  0  0  0]\n",
      " [ 3  6  1  0]\n",
      " [ 1  3  3  0]\n",
      " [ 1  3  0  1]]\n",
      "Krippendorff's alpha for regulation_type: 0.6115743011280039\n",
      "Mismatches between coders for regulation_type:\n",
      "    ticker  regulation_type_coder1  regulation_type_coder2\n",
      "0     MGY                       1                       0\n",
      "3     EOG                       1                       0\n",
      "12    CNP                       2                       1\n",
      "13   DWSN                       2                       1\n",
      "20   SMLP                       3                       0\n",
      "22    CNX                       3                       1\n",
      "27   LBRT                       2                       0\n",
      "32   NINE                       1                       2\n",
      "33    RRC                       1                       0\n",
      "36   PTEN                       2                       1\n",
      "39     SM                       3                       1\n",
      "45    NOG                       3                       1\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Confusion Matrix for regulation_cost:\n",
      " [[32  1  0]\n",
      " [ 4 12  0]\n",
      " [ 1  0  0]]\n",
      "Krippendorff's alpha for regulation_cost: 0.619067977768277\n",
      "Mismatches between coders for regulation_cost:\n",
      "    ticker  regulation_cost_coder1  regulation_cost_coder2\n",
      "12    CNP                       1                       0\n",
      "13   DWSN                       2                       0\n",
      "20   SMLP                       1                       0\n",
      "25   ARLP                       0                       1\n",
      "27   LBRT                       1                       0\n",
      "33    RRC                       1                       0\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Confusion Matrix for federal_regulation:\n",
      " [[32  1]\n",
      " [ 7 10]]\n",
      "Krippendorff's alpha for federal_regulation: 0.6071428571428572\n",
      "Mismatches between coders for federal_regulation:\n",
      "    ticker  federal_regulation_coder1  federal_regulation_coder2\n",
      "12    CNP                          1                          0\n",
      "20   SMLP                          1                          0\n",
      "26   KLXE                          1                          0\n",
      "27   LBRT                          1                          0\n",
      "33    RRC                          1                          0\n",
      "39     SM                          1                          0\n",
      "40    HCC                          0                          1\n",
      "45    NOG                          1                          0\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Confusion Matrix for state_regulation:\n",
      " [[37  0]\n",
      " [ 7  6]]\n",
      "Krippendorff's alpha for state_regulation: 0.5497076023391813\n",
      "Mismatches between coders for state_regulation:\n",
      "    ticker  state_regulation_coder1  state_regulation_coder2\n",
      "12    CNP                        1                        0\n",
      "20   SMLP                        1                        0\n",
      "26   KLXE                        1                        0\n",
      "27   LBRT                        1                        0\n",
      "39     SM                        1                        0\n",
      "45    NOG                        1                        0\n",
      "48   EVRG                        1                        0\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Confusion Matrix for local_regulation:\n",
      " [[43  0]\n",
      " [ 4  3]]\n",
      "Krippendorff's alpha for local_regulation: 0.56\n",
      "Mismatches between coders for local_regulation:\n",
      "    ticker  local_regulation_coder1  local_regulation_coder2\n",
      "26   KLXE                        1                        0\n",
      "27   LBRT                        1                        0\n",
      "29    KRP                        1                        0\n",
      "33    RRC                        1                        0\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the categories to analyze\n",
    "categories = ['regulation_present','regulation_type', 'regulation_cost', 'federal_regulation', 'state_regulation', 'local_regulation']\n",
    "\n",
    "# Loop through each category and calculate the confusion matrix and Krippendorff's alpha\n",
    "for category in categories:\n",
    "    coder1 = sample[f'{category}_coder1']\n",
    "    coder2 = sample[f'{category}_coder2']\n",
    "    \n",
    "    # Calculate and display the confusion matrix\n",
    "    conf_matrix = confusion_matrix(coder1, coder2)\n",
    "    print(f\"Confusion Matrix for {category}:\\n\", conf_matrix)\n",
    "    \n",
    "    # Prepare data for Krippendorff's alpha\n",
    "    data_for_alpha = [coder1.values, coder2.values]\n",
    "    \n",
    "    # Calculate and display Krippendorff's alpha\n",
    "    alpha = krippendorff.alpha(reliability_data=data_for_alpha)\n",
    "    print(f\"Krippendorff's alpha for {category}:\", alpha)\n",
    "    \n",
    "    # Display mismatches\n",
    "    mismatches = sample[coder1 != coder2]\n",
    "    print(f\"Mismatches between coders for {category}:\\n\", mismatches[['ticker', f'{category}_coder1', f'{category}_coder2']])\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Discussion of results\n",
    "\n",
    "The results reveal a pattern in my coding approach: I tended to over-code instances compared to Coder 2, with very few cases where Coder 2 identified an instance that I missed. This suggests a systematic difference in our interpretations, likely due to my broader reading of the categories.\n",
    "\n",
    "\n",
    "#### regulation_present\n",
    "\n",
    "For the **regulation_present** category, we achieved the highest Krippendorff's alpha score of 0.75 which is not too high. This makes sense, as this is the broadest category, serving as a foundational category for the more specific sub-categories. If we disagree at this foundational level, disagreements in the subsequent sub-categories are expected by design. For example, there was a case where Coder 2 didn’t consider the regulation to pertain to the environment, while I did. That decision affected our coding in related columns for federal, state, and local levels, highlighting how initial disagreements can cascade into multiple coding differences. In most ohter categories the Krippendorff's alpha score was about 0.6 so quite low, but again this is also affected by the construct of the categories. \n",
    "\n",
    "Upon examining discrepancies, I identified six instances where I coded \"1\" and Coder 2 coded \"0.\" In three of these cases, the environmental regulation was less prominent in the text, possibly buried among other information. In the remaining three cases, the differences were more nuanced. For example, two of these cases involved hydraulic fracturing. One instance discussed permitting and leasing practices, while the other focused on health risks associated with handling hydraulic fracture sand. In the first case, the regulation was phrased as: “Acting Secretary for the Department of the Interior signed an order effectively suspending new fossil fuel leasing and permitting on federal lands.\" I interpreted this as an environmental/energy regulation, as it directly relates to energy practices on public lands, and i think it should be coded as \"1\". However, in the other instance, the text discussed \"the actual or perceived health risks of handling hydraulic fracture sand,\" which my peer did not classify as environmental regulation. Upon further discussion, we agreed that this second regulation, while affecting energy firms, stems from health and safety concerns rather than environmental ones. Another interesting discrepancy involved an SEC rule requiring companies to report environmental risks. This was challenging, but ultimately, I decided to code it as \"0\" since it does not alter firms’ operational practices but rather their reporting requirements. The key takeaway here is the importance of discerning the intent behind the regulation rather than simply identifying sector-related keywords. If a regulation impacts energy firms purely as a byproduct of their industry (such as health and safety), it may not fit under regulation_present unless environmental or energy concerns are explicitly the focus.\n",
    "\n",
    "Given these observations, I plan to refine my codebook definition for regulation_present to be:\n",
    "\n",
    " - **regulation_present:** *This binary variable captures the presence of either environmental or energy regulation specifically within the text. It must be clear that the regulation is motivated by environmental or energy concerns, rather than general regulatory impacts that incidentally affect energy or environmental firms.*\n",
    "\n",
    "This refined definition should help reduce ambiguity and improve coder alignment by focusing on the regulatory intention rather than incidental industry effects.\n",
    "\n",
    "\n",
    "#### regulation_cost\n",
    "\n",
    "This category turned out to be somewhat redundant and poorly defined. In essence, any mention of regulatory risk can imply a potential cost to the firm, given the nature of 10-K risk sections. For example, we did not have a clear concensus on whether an implicit costs such as \"delays\" should be coded as 1 or 0. My intention with regulation_cost was to replicate a category used in Satuner et al. (2023), a dataset I am trying to adapt for 10-Ks instead of earnings calls. However, in 10-K filings, nearly every mention of environmental regulation poses a potential or implied cost, making this category less useful as a distinctive measure. F Additionally, my confusion matrix is 3x3 due to a typo (\"2\" instead of \"1\" or \"0\").\n",
    "\n",
    "#### regulation_type\n",
    "This category proved to be challenging because environmental and energy regulations are often discussed together. Differentiating between the two can be difficult, as they are interlinked (e.g., emissions restrictions often impact energy production). The distinction became murky in cases where the regulation talked about both emissions limitations and restrictions on oil and gas production.\n",
    "\n",
    "In retrospect, it might be more insightful to remove **regulation_type** as a hand-coded category and instead use a topic modeling approach on the text chunks that include any form of environmental or energy regulation. This approach could reveal natural clusters of topics and identify distinguishing words, providing a more nuanced understanding of regulatory themes than manual coding could achieve.\n",
    "\n",
    "If I were to keep this category, a refined codebook definition might specify:\n",
    "\n",
    "*Environmental Regulation: Focuses on controlling or reducing emissions, pollutants, and environmental impact.*\n",
    "\n",
    "*Energy Regulation: Pertains to rules affecting energy production, transmission, and extraction processes (e.g., hydraulic fracturing regulations, grid management policies), moderating enrgy cost, availability, etc.*\n",
    "\n",
    "#### Federal, State, and Local Regulation Levels\n",
    "For the levels of regulation (federal_regulation, state_regulation, local_regulation), most discrepancies arose from cases where we didn’t initially agree on whether the regulation was environmental or energy-related. Excluding those instances, the primary difference was that the second coder occasionally missed mentions of \"stae regulation\" or \"local regulation\" within the text, rather than a fundamental disagreement on whether it applied. This underscores the importance of thorough and detailed coding for levels of government, especially for local ordinances, which can be subtle.\n",
    "\n",
    "#### Reflection on Coding Process\n",
    "\n",
    "This exercise highlighted some practical challenges with manual coding. Human coders can experience fatigue, which may impact attention and accuracy, especially when coding lengthy text chunks. I initially broke the text into 10-sentence chunks, but I now realize that shorter chunks (e.g., 5 sentences) might be more manageable. However, there’s a trade-off: shorter chunks risk losing context that spans multiple sentences, which could be crucial for identifying environmental or energy regulation mentions.\n",
    "\n",
    "Additionally, the value of knowledgeable coders became apparent. Recognizing specific agencies, acronyms, and regulatory bodies (e.g., distinguishing federal agencies from state/local entities) requires familiarity with the subject matter. Although my codebook covered some of this, coders sometimes had to research terms to ensure accuracy. This experience underlines the importance of using well-prepared coders who can apply domain knowledge effectively for accurate results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
